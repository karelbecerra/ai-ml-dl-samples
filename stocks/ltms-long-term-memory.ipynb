{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Stock Market Data\n",
    "Data comes from Microsoft or TATA Consulting firm. Data includes\n",
    "- Open value\n",
    "- Close value\n",
    "- Highest daily value\n",
    "- Lowest daily value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './../data/stocks/'\n",
    "stock = 'Microsoft'\n",
    "\n",
    "if stock == 'Microsoft':\n",
    "  dataset_file = data_folder + 'microsoft_stocks.csv'\n",
    "  close_column ='Adj Close'                   # Close column name\n",
    "  volume_column = 'Volume'                    # Volumen column name\n",
    "else:\n",
    "  dataset_file = data_folder + 'NSE_TATAGLOBAL11.csv'\n",
    "  close_column ='Close'                       # Close column name\n",
    "  volume_column = 'Total Trade Quantity'      # Volumen column name\n",
    "\n",
    "# Read dataset and sort date ascending\n",
    "df=pd.read_csv(dataset_file, na_values=['null'], index_col='Date', parse_dates=True)\n",
    "df = df.sort_index(ascending=True, axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify null or empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify null or empty values\n",
    "print(\"Null values?: \", df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize stocks historical closing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting closing: Adj Close or Close column\n",
    "df[close_column].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Target Variable (expected output) and Features (input values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable is closing value\n",
    "close_target = pd.DataFrame(df[close_column])\n",
    "\n",
    "# Features includes all related data\n",
    "features_columns = ['Open', 'High', 'Low', volume_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling features (norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling form 1 to 0\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "features = scaler.fit_transform(df[features_columns])\n",
    "feature = pd.DataFrame(columns=features_columns, data=features, index=df.index)\n",
    "feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting to datasets in 10 buckets\n",
    "timesplit = TimeSeriesSplit(n_splits=10)\n",
    "for train_index, test_index in timesplit.split(features):\n",
    "        X_train, X_test = features[:len(train_index)], features[len(train_index): (len(train_index)+len(test_index))]\n",
    "        y_train, y_test = close_target[:len(train_index)].values.ravel(), close_target[len(train_index): (len(train_index)+len(test_index))].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data shaping for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = X_train.shape[0], 1, X_train.shape[1]\n",
    "X_train = np.array(X_train).reshape(shape)\n",
    "X_test = np.array(X_test).reshape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, X_train.shape[1]), activation='relu', return_sequences=False))\n",
    "#model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "#model.add(LSTM(units=50))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n",
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing ground truth vs predicted value (Close value)\n",
    "We print some days in the past and predicted value together with expected value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some past(past) closing values to present (today). Then print target/predicted values\n",
    "past = int(len(train_index)-len(train_index)/10)\n",
    "today = len(train_index)\n",
    "train = close_target[past:today]\n",
    "test = close_target[today:]\n",
    "test['Predictions'] = y_pred\n",
    "plt.plot(train[close_column])\n",
    "plt.plot(test[[close_column, 'Predictions']])\n",
    "plt.title(\"Prediction\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('USD')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
